{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST-SCRIPT for EVALUATION of ASR systems\n",
    "\n",
    "- For details on the low level functions, see also:\n",
    "  + distance_test: example usage of the levenshtein() and edit_distance() routines\n",
    "  + normalization_test: example usage of text normalization\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do all the imports\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import evalign as eva\n",
    "import pkg_resources\n",
    "resources = pkg_resources.resource_filename('evalign', 'data/')\n",
    "testdata = \"testdata/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **eval_corpus()** : Main Scoring Routine\n",
    "\n",
    "This routine takes two aligned lists of utterances for hypothesis and reference as input\n",
    "and returns results into a results dictionary.   \n",
    "Both word and character error rates can be computed.\n",
    "The results dictionary contains the global error rate, detailed numbers of SUBS, INS, DEL, ..   \n",
    "Optionally it will also contain the alignments between input and reference and a summary of the errors that were made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_utt = [\"Minister Daems stelt de vakbonden voor de keuze .\",\" Good Morning Vietnam\"]\n",
    "hyp_utt = [\"minister Daems geeft de vakbonden geen keuze\",\"jolly good day to Nam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate: 83.33% \n",
      "Error Details: #S=6 #I=2 #D=2\n",
      "Edit Distance: 10.60 \n",
      "Tokens (HYP): 12    (REF): 12 \n",
      "Utterances: 2\n"
     ]
    }
   ],
   "source": [
    "# by default WORD error rates will be computed\n",
    "results = eva.eval_corpus(hyp_utt,ref_utt)\n",
    "#print(results)\n",
    "assert(results['total']==10)\n",
    "eva.pp_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Error Rates\n",
    "Character error rates are computed by passing the argument TOKEN=CHAR.  \n",
    "Note that punctuation is first removed and all white space is reduced to single blanks.   \n",
    "There is an option to maintain the input character sequence as given, by using TOKEN=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate: 42.86% \n",
      "Error Details: #S=19 #I=3 #D=8\n",
      "Edit Distance: 31.90 \n",
      "Tokens (HYP): 65    (REF): 70 \n",
      "Utterances: 2\n",
      "Error Rate: 42.03% \n",
      "Error Details: #S=19 #I=3 #D=7\n",
      "Edit Distance: 30.90 \n",
      "Tokens (HYP): 65    (REF): 69 \n",
      "Utterances: 2\n"
     ]
    }
   ],
   "source": [
    "# character error rates\n",
    "results = eva.eval_corpus(hyp_utt,ref_utt,TOKEN=None)\n",
    "eva.pp_results(results)\n",
    "assert(results['total']==30)\n",
    "# character error rates\n",
    "results = eva.eval_corpus(hyp_utt,ref_utt,TOKEN='CHAR')\n",
    "eva.pp_results(results)\n",
    "assert(results['total']==29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ALIGNMENTS\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>S</th>\n",
       "      <th>S</th>\n",
       "      <th>H</th>\n",
       "      <th>S</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>D</th>\n",
       "      <th>D</th>\n",
       "      <th>D</th>\n",
       "      <th>D</th>\n",
       "      <th>S</th>\n",
       "      <th>S</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>m</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "      <td>a</td>\n",
       "      <td>e</td>\n",
       "      <td>m</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>g</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td></td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "      <td></td>\n",
       "      <td>v</td>\n",
       "      <td>a</td>\n",
       "      <td>k</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>n</td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>g</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td></td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>u</td>\n",
       "      <td>z</td>\n",
       "      <td>e</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>M</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "      <td>a</td>\n",
       "      <td>e</td>\n",
       "      <td>m</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>l</td>\n",
       "      <td>t</td>\n",
       "      <td></td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "      <td></td>\n",
       "      <td>v</td>\n",
       "      <td>a</td>\n",
       "      <td>k</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>n</td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td></td>\n",
       "      <td>v</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td></td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "      <td>_</td>\n",
       "      <td></td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>u</td>\n",
       "      <td>z</td>\n",
       "      <td>e</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S  H  H  H  H  H  H  H  H  H  H  H  H  H  H  S  S  H  S  H  H  H  H  H  H  \\\n",
       "x  m  i  n  i  s  t  e  r     D  a  e  m  s     g  e  e  f  t     d  e     v   \n",
       "y  M  i  n  i  s  t  e  r     D  a  e  m  s     s  t  e  l  t     d  e     v   \n",
       "\n",
       "   H  H  H  H  H  H  H  H  H  D  D  D  D  S  S  H  I  H  H  H  H  H  H  D  \n",
       "x  a  k  b  o  n  d  e  n     _  _  _  _  g  e  e  n     k  e  u  z  e  _  \n",
       "y  a  k  b  o  n  d  e  n     v  o  o  r     d  e  _     k  e  u  z  e     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>S</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>S</th>\n",
       "      <th>S</th>\n",
       "      <th>H</th>\n",
       "      <th>S</th>\n",
       "      <th>H</th>\n",
       "      <th>S</th>\n",
       "      <th>S</th>\n",
       "      <th>I</th>\n",
       "      <th>S</th>\n",
       "      <th>S</th>\n",
       "      <th>S</th>\n",
       "      <th>H</th>\n",
       "      <th>D</th>\n",
       "      <th>S</th>\n",
       "      <th>S</th>\n",
       "      <th>S</th>\n",
       "      <th>S</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>_</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>l</td>\n",
       "      <td>l</td>\n",
       "      <td>y</td>\n",
       "      <td></td>\n",
       "      <td>g</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>y</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>t</td>\n",
       "      <td>o</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td></td>\n",
       "      <td>G</td>\n",
       "      <td>o</td>\n",
       "      <td>_</td>\n",
       "      <td>o</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>_</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "      <td></td>\n",
       "      <td>V</td>\n",
       "      <td>i</td>\n",
       "      <td>e</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   D  S  H  I  S  S  H  S  H  S  S  I  S  S  S  H  D  S  S  S  S  H  H\n",
       "x  _  j  o  l  l  y     g  o  o  d     d  a  y     _  t  o     N  a  m\n",
       "y     G  o  _  o  d     M  o  r  n  _  i  n  g     V  i  e  t  n  a  m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ERRORS\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g</td>\n",
       "      <td>s</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>t</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f</td>\n",
       "      <td>l</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_</td>\n",
       "      <td>v</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_</td>\n",
       "      <td>o</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_</td>\n",
       "      <td>o</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>_</td>\n",
       "      <td>r</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>g</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>n</td>\n",
       "      <td>_</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>_</td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>_</td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>j</td>\n",
       "      <td>G</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>l</td>\n",
       "      <td>_</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>y</td>\n",
       "      <td>d</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>g</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>d</td>\n",
       "      <td>i</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>y</td>\n",
       "      <td>g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>_</td>\n",
       "      <td>V</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>t</td>\n",
       "      <td>i</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td></td>\n",
       "      <td>t</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>N</td>\n",
       "      <td>n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x  y  E\n",
       "0   m  M  S\n",
       "1   g  s  S\n",
       "2   e  t  S\n",
       "3   f  l  S\n",
       "4   _  v  D\n",
       "5   _  o  D\n",
       "6   _  o  D\n",
       "7   _  r  D\n",
       "8   g     S\n",
       "9   e  d  S\n",
       "10  n  _  I\n",
       "11  _     D\n",
       "12  _     D\n",
       "13  j  G  S\n",
       "14  l  _  I\n",
       "15  l  o  S\n",
       "16  y  d  S\n",
       "17  g  M  S\n",
       "18  o  r  S\n",
       "19  d  n  S\n",
       "20     _  I\n",
       "21  d  i  S\n",
       "22  a  n  S\n",
       "23  y  g  S\n",
       "24  _  V  D\n",
       "25  t  i  S\n",
       "26  o  e  S\n",
       "27     t  S\n",
       "28  N  n  S"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# When adding the option ALGIN=True, alignments and error details will be in the results structure\n",
    "# you can also print alignments and the errors, \n",
    "results = eva.eval_corpus(hyp_utt,ref_utt,TOKEN='CHAR',ALIGN=True)\n",
    "eva.pp_results(results,['align','errors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate: 54.55% \n",
      "Error Details: #S=3 #I=2 #D=1\n",
      "Edit Distance: 6.30 \n",
      "Tokens (HYP): 12    (REF): 11 \n",
      "Utterances: 2\n",
      "\n",
      "ALIGNMENTS\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>S</th>\n",
       "      <th>H</th>\n",
       "      <th>H</th>\n",
       "      <th>D</th>\n",
       "      <th>S</th>\n",
       "      <th>H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>minister</td>\n",
       "      <td>daems</td>\n",
       "      <td>geeft</td>\n",
       "      <td>de</td>\n",
       "      <td>vakbonden</td>\n",
       "      <td>_</td>\n",
       "      <td>geen</td>\n",
       "      <td>keuze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>minister</td>\n",
       "      <td>daems</td>\n",
       "      <td>stelt</td>\n",
       "      <td>de</td>\n",
       "      <td>vakbonden</td>\n",
       "      <td>voor</td>\n",
       "      <td>de</td>\n",
       "      <td>keuze</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          H      H      S   H          H     D     S      H\n",
       "x  minister  daems  geeft  de  vakbonden     _  geen  keuze\n",
       "y  minister  daems  stelt  de  vakbonden  voor    de  keuze"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>S</th>\n",
       "      <th>H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>jolly</td>\n",
       "      <td>good</td>\n",
       "      <td>day</td>\n",
       "      <td>to</td>\n",
       "      <td>vietnam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>_</td>\n",
       "      <td>good</td>\n",
       "      <td>_</td>\n",
       "      <td>morning</td>\n",
       "      <td>vietnam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       I     H    I        S        H\n",
       "x  jolly  good  day       to  vietnam\n",
       "y      _  good    _  morning  vietnam"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# with text normalization - implemented as a pipeline process\n",
    "norm_x1 = eva.Normalizer()\n",
    "norm_x1.add_pipe(\"RemovePunctuation\")                  # remove most common punctuation\n",
    "norm_x1.add_pipe(\"SubstituteWords\",{\"Nam\":\"Vietnam\"})  # normalize synonyms\n",
    "norm_x1.add_pipe(\"Lower\")                              # decapitalize\n",
    "\n",
    "results = eva.eval_corpus(hyp_utt,ref_utt,norm=norm_x1,ALIGN=True)\n",
    "eva.pp_results(results,['results','align'])\n",
    "assert(results['total']==6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION from a TEXT CORPUS\n",
    "Combine:\n",
    "- **read_corpus()** to read reference and hypothesis texts from file and splits lines\n",
    "- **eval_corpus()** to do the evaluation\n",
    "- optionally define text normalization in a **Normalizer** object to be applied to test and reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CGN: raw word error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw (Word) Error Rate\n",
      "Error Rate: 36.43% \n",
      "Error Details: #S=34 #I=7 #D=10\n",
      "Edit Distance: 54.40 \n",
      "Tokens (HYP): 137    (REF): 140 \n",
      "Utterances: 5\n"
     ]
    }
   ],
   "source": [
    "ref_fname = testdata+ \"cgndev1_ref.txt\"\n",
    "hyp_fname = testdata + \"cgndev1_asr1.txt\"\n",
    "ref_utt = eva.read_corpus(ref_fname)\n",
    "hyp_utt = eva.read_corpus(hyp_fname)\n",
    "\n",
    "print(\"\\nRaw (Word) Error Rate\")\n",
    "results = eva.eval_corpus(hyp_utt,ref_utt)\n",
    "eva.pp_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CGN: with text normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error Rate after normalization and allowing for compounds\n",
      "Error Rate: 28.47% \n",
      "Error Details: #S=25 #I=4 #D=10\n",
      "Accepted Compounds: #C=2\n",
      "Edit Distance: 41.90 \n",
      "Tokens (HYP): 131    (REF): 137 \n",
      "Utterances: 5\n"
     ]
    }
   ],
   "source": [
    "# 1. Load substitution patterns  from files \n",
    "cgn_fillers = eva.LoadSubstitutionsFromFile(resources+'cgn_fillers.lst')\n",
    "nl_abbrev = eva.LoadSubstitutionsFromFile(resources+'nl_abbrev.lst')\n",
    "nl_getallen100 = eva.LoadSubstitutionsFromFile(resources+'nl_getallen100.lst')\n",
    "nbest = eva.LoadSubstitutionsFromFile(resources+'nbest.lst')\n",
    "# 2. Create the Normalizer object  \n",
    "norm_nl = eva.Normalizer()\n",
    "norm_nl.add_pipe(\"RemovePunctuation\")\n",
    "norm_nl.add_pipe(\"SubstituteWords\",nl_abbrev)\n",
    "norm_nl.add_pipe(\"SubstituteWords\",cgn_fillers)\n",
    "norm_nl.add_pipe(\"Substitute\",nl_getallen100)\n",
    "norm_nl.add_pipe(\"Substitute\",nbest)\n",
    "norm_nl.add_pipe(\"RemoveTags\")\n",
    "norm_nl.add_pipe(\"Lower\")\n",
    "norm_nl.add_pipe(\"RemoveWhiteSpace\")\n",
    "#norm_nl.info()\n",
    "##\n",
    "print(\"\\nError Rate after normalization and allowing for compounds\")\n",
    "results = eva.eval_corpus(hyp_utt,ref_utt,norm=norm_nl,CMPND=['','-'])\n",
    "eva.pp_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CGN: Character Error Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw (Character) Error Rate\n",
      "Error Rate: 17.74% \n",
      "Error Details: #S=46 #I=50 #D=47\n",
      "Edit Distance: 147.60 \n",
      "Tokens (HYP): 809    (REF): 806 \n",
      "Utterances: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRaw (Character) Error Rate\")\n",
    "results = eva.eval_corpus(hyp_utt,ref_utt,TOKEN='CHAR',ALIGN=True)\n",
    "eva.pp_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis\n",
    "Remember to set the ALIGN flag should be set.   ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate after Normalization WITHOUT Compounds\n",
      "Error Rate: 31.39% \n",
      "Error Details: #S=27 #I=5 #D=11\n",
      "Edit Distance: 45.70 \n",
      "Tokens (HYP): 131    (REF): 137 \n",
      "Utterances: 5\n",
      "Error Rate after Normalization WITH Compounds\n",
      "Error Rate: 28.47% \n",
      "Error Details: #S=25 #I=4 #D=10\n",
      "Accepted Compounds: #C=2\n",
      "Edit Distance: 41.90 \n",
      "Tokens (HYP): 131    (REF): 137 \n",
      "Utterances: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Error Rate after Normalization WITHOUT Compounds\")\n",
    "res1 = eva.eval_corpus(hyp_utt,ref_utt,norm=norm_nl,ALIGN=True)\n",
    "eva.pp_results(res1)\n",
    "#\n",
    "print(\"Error Rate after Normalization WITH Compounds\")\n",
    "res2 = eva.eval_corpus(hyp_utt,ref_utt,norm=norm_nl,CMPND=['','-'],ALIGN=True)\n",
    "eva.pp_results(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALIGNMENT of sentence(0) for test 2\n",
      "[('alle', 'alle'), ('opleidingen', 'opleidingen'), ('die', 'die'), ('van', 'van'), ('de', 'de'), ('eerste', 'eerste'), ('cyclus', 'cyclus'), ('aan', 'aan'), ('het', 'het'), ('trucje', 'ruca'), ('of', 'of'), ('de', 'de'), ('ufsia', 'ufsia'), ('doorstromen', 'doorstromen'), ('naar', 'naar'), ('het', 'de'), ('tweede', 'tweede'), ('cyclus', 'cyclus'), ('van', 'van'), ('de', 'de'), ('uia', 'uia'), ('zullen', 'zullen'), ('per', 'per'), ('één', 'één'), ('oktober', 'oktober'), ('negenennegentig', 'negenennegentig'), ('door', 'door'), ('faculteiten', 'facultaire'), ('eu-beleid', '_'), ('organen', 'ua-beleidsorganen'), ('worden', 'worden'), ('gestuwd', 'gestuurd')]\n"
     ]
    }
   ],
   "source": [
    "# alignment of first sentence for test2\n",
    "print('ALIGNMENT of sentence(0) for test 2')\n",
    "print(res2['align'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors in test1\n",
      "\n",
      "ERRORS\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trucje</td>\n",
       "      <td>ruca</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>het</td>\n",
       "      <td>de</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>faculteiten</td>\n",
       "      <td>facultaire</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eu-beleid</td>\n",
       "      <td>_</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>organen</td>\n",
       "      <td>ua-beleidsorganen</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gestuwd</td>\n",
       "      <td>gestuurd</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>verdeling</td>\n",
       "      <td>verdunning</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>eis</td>\n",
       "      <td>_</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>schaal</td>\n",
       "      <td>eischaal</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>collecties</td>\n",
       "      <td>eicollecties</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>_</td>\n",
       "      <td>hu</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>_</td>\n",
       "      <td>'k</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>broertjes</td>\n",
       "      <td>british</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>music</td>\n",
       "      <td>museum</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>worden</td>\n",
       "      <td>werden</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>eis</td>\n",
       "      <td>_</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>schalen</td>\n",
       "      <td>eischalen</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nog</td>\n",
       "      <td>hoe</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>_</td>\n",
       "      <td>dat</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>totti</td>\n",
       "      <td>die</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>_</td>\n",
       "      <td>en</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>een</td>\n",
       "      <td>die</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>deel</td>\n",
       "      <td>dan</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>_</td>\n",
       "      <td>de</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>schaal</td>\n",
       "      <td>eischalen</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>_</td>\n",
       "      <td>we</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>_</td>\n",
       "      <td>moeten</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ze</td>\n",
       "      <td>zeker</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>zeggen</td>\n",
       "      <td>denk</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>denkt</td>\n",
       "      <td>ik</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>_</td>\n",
       "      <td>verder</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>_</td>\n",
       "      <td>gaan</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>verdergaan</td>\n",
       "      <td>met</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>_</td>\n",
       "      <td>mensen</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>_</td>\n",
       "      <td>voor</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>'s</td>\n",
       "      <td>lezingen</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>lezing</td>\n",
       "      <td>ook</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ze</td>\n",
       "      <td>zij</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>en</td>\n",
       "      <td>ren</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>fladderen</td>\n",
       "      <td>_</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>de</td>\n",
       "      <td>flodderende</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>beet</td>\n",
       "      <td>_</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>pak</td>\n",
       "      <td>beetpak</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              x                  y  E\n",
       "0        trucje               ruca  S\n",
       "1           het                 de  S\n",
       "2   faculteiten         facultaire  S\n",
       "3     eu-beleid                  _  I\n",
       "4       organen  ua-beleidsorganen  S\n",
       "5       gestuwd           gestuurd  S\n",
       "6     verdeling         verdunning  S\n",
       "7           eis                  _  I\n",
       "8        schaal           eischaal  S\n",
       "9    collecties       eicollecties  S\n",
       "10            _                 hu  D\n",
       "11            _                 'k  D\n",
       "12    broertjes            british  S\n",
       "13        music             museum  S\n",
       "14       worden             werden  S\n",
       "15          eis                  _  I\n",
       "16      schalen          eischalen  S\n",
       "17          nog                hoe  S\n",
       "18            _                dat  D\n",
       "19        totti                die  S\n",
       "20            _                 en  D\n",
       "21          een                die  S\n",
       "22         deel                dan  S\n",
       "23            _                 de  D\n",
       "24       schaal          eischalen  S\n",
       "25            _                 we  D\n",
       "26            _             moeten  D\n",
       "27           ze              zeker  S\n",
       "28       zeggen               denk  S\n",
       "29        denkt                 ik  S\n",
       "30            _             verder  D\n",
       "31            _               gaan  D\n",
       "32   verdergaan                met  S\n",
       "33            _             mensen  D\n",
       "34            _               voor  D\n",
       "35           's           lezingen  S\n",
       "36       lezing                ook  S\n",
       "37           ze                zij  S\n",
       "38           en                ren  S\n",
       "39    fladderen                  _  I\n",
       "40           de        flodderende  S\n",
       "41         beet                  _  I\n",
       "42          pak            beetpak  S"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Errors and Compounds in test2\n",
      "\n",
      "ERRORS\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trucje</td>\n",
       "      <td>ruca</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>het</td>\n",
       "      <td>de</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>faculteiten</td>\n",
       "      <td>facultaire</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eu-beleid</td>\n",
       "      <td>_</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>organen</td>\n",
       "      <td>ua-beleidsorganen</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gestuwd</td>\n",
       "      <td>gestuurd</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>verdeling</td>\n",
       "      <td>verdunning</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>eis</td>\n",
       "      <td>_</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>schaal</td>\n",
       "      <td>eischaal</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>collecties</td>\n",
       "      <td>eicollecties</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>_</td>\n",
       "      <td>hu</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>_</td>\n",
       "      <td>'k</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>broertjes</td>\n",
       "      <td>british</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>music</td>\n",
       "      <td>museum</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>worden</td>\n",
       "      <td>werden</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>eis</td>\n",
       "      <td>_</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>schalen</td>\n",
       "      <td>eischalen</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nog</td>\n",
       "      <td>hoe</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>_</td>\n",
       "      <td>dat</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>totti</td>\n",
       "      <td>die</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>_</td>\n",
       "      <td>en</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>een</td>\n",
       "      <td>die</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>deel</td>\n",
       "      <td>dan</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>_</td>\n",
       "      <td>de</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>schaal</td>\n",
       "      <td>eischalen</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>_</td>\n",
       "      <td>we</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>_</td>\n",
       "      <td>moeten</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ze</td>\n",
       "      <td>zeker</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>zeggen</td>\n",
       "      <td>denk</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>denkt</td>\n",
       "      <td>ik</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>verdergaan</td>\n",
       "      <td>verder+gaan</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>_</td>\n",
       "      <td>met</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>_</td>\n",
       "      <td>mensen</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>'s</td>\n",
       "      <td>voor</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>_</td>\n",
       "      <td>lezingen</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>lezing</td>\n",
       "      <td>ook</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ze</td>\n",
       "      <td>zij</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>en</td>\n",
       "      <td>ren</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>fladderen</td>\n",
       "      <td>_</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>de</td>\n",
       "      <td>flodderende</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>beet+pak</td>\n",
       "      <td>beetpak</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              x                  y  E\n",
       "0        trucje               ruca  S\n",
       "1           het                 de  S\n",
       "2   faculteiten         facultaire  S\n",
       "3     eu-beleid                  _  I\n",
       "4       organen  ua-beleidsorganen  S\n",
       "5       gestuwd           gestuurd  S\n",
       "6     verdeling         verdunning  S\n",
       "7           eis                  _  I\n",
       "8        schaal           eischaal  S\n",
       "9    collecties       eicollecties  S\n",
       "10            _                 hu  D\n",
       "11            _                 'k  D\n",
       "12    broertjes            british  S\n",
       "13        music             museum  S\n",
       "14       worden             werden  S\n",
       "15          eis                  _  I\n",
       "16      schalen          eischalen  S\n",
       "17          nog                hoe  S\n",
       "18            _                dat  D\n",
       "19        totti                die  S\n",
       "20            _                 en  D\n",
       "21          een                die  S\n",
       "22         deel                dan  S\n",
       "23            _                 de  D\n",
       "24       schaal          eischalen  S\n",
       "25            _                 we  D\n",
       "26            _             moeten  D\n",
       "27           ze              zeker  S\n",
       "28       zeggen               denk  S\n",
       "29        denkt                 ik  S\n",
       "30   verdergaan        verder+gaan  C\n",
       "31            _                met  D\n",
       "32            _             mensen  D\n",
       "33           's               voor  S\n",
       "34            _           lezingen  D\n",
       "35       lezing                ook  S\n",
       "36           ze                zij  S\n",
       "37           en                ren  S\n",
       "38    fladderen                  _  I\n",
       "39           de        flodderende  S\n",
       "40     beet+pak            beetpak  C"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compounds found in test2\n",
      "[('verdergaan', 'verder+gaan', 'C'), ('beet+pak', 'beetpak', 'C')]\n"
     ]
    }
   ],
   "source": [
    "print('Errors in test1')\n",
    "eva.pp_results(res1,'errors')\n",
    "\n",
    "print('\\nAll Errors and Compounds in test2')\n",
    "eva.pp_results(res2,'errors')\n",
    "\n",
    "print('\\nCompounds found in test2')\n",
    "errc = [ error for error in res2['errors'] if (error[2] in ['C']) ]\n",
    "print(errc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Extra Functionalities in **read_corpus()** \n",
    "+ by default it assumes LineFeeds to separate utterance and matching utterances in test and hypothesis\n",
    "+ alternatively it accepts files in which utterances start with a unique KEY\n",
    "    + a selection of utterances defined by keys can be made using **select_from_corpus()** \n",
    "    + a selection of matching utterances can be made with **match_corpora**\n",
    "    + this is particularly handy if you want to evaluate a small test set , using a larger reference corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING(select_from_corpus): could not find utt with key:  v60073_nbest-dev-2008-bn-vl_001_000000-003073\n",
      "WARNING(select_from_corpus): could not find utt with key:  v60073_nbest-dev-2008-bn-vl_001_044106-051592\n",
      "['v60049_nbest-dev-2008-bn-vl_004_002319-005151', 'v60049_nbest-dev-2008-bn-vl_004_012243-022033', 'v60073_nbest-dev-2008-bn-vl_001_000000-003073', 'v60073_nbest-dev-2008-bn-vl_001_044106-051592', 'v60073_nbest-dev-2008-bn-vl_001_055116-060351', 'v60073_nbest-dev-2008-bn-vl_006_000000-003472', 'v60074_nbest-dev-2008-bn-vl_001_003093-012772'] ['v60049_nbest-dev-2008-bn-vl_004_002319-005151', 'v60049_nbest-dev-2008-bn-vl_004_012243-022033', 'v60073_nbest-dev-2008-bn-vl_001_055116-060351', 'v60073_nbest-dev-2008-bn-vl_006_000000-003472', 'v60074_nbest-dev-2008-bn-vl_001_003093-012772', 'v60074_nbest-dev-2008-bn-vl_001_012792-017385'] ['v60049_nbest-dev-2008-bn-vl_004_002319-005151', 'v60049_nbest-dev-2008-bn-vl_004_012243-022033', 'v60073_nbest-dev-2008-bn-vl_001_055116-060351', 'v60073_nbest-dev-2008-bn-vl_006_000000-003472', 'v60074_nbest-dev-2008-bn-vl_001_003093-012772']\n"
     ]
    }
   ],
   "source": [
    "ref_utt, ref_ids = eva.read_corpus(testdata+\"demo1_ref.txt\",KEYS=True)\n",
    "hyp_utt, hyp_ids = eva.read_corpus(testdata+\"demo1_hyp.txt\",KEYS=True)\n",
    "#\n",
    "# in this example there are multiple anomalies that need to be resolved \n",
    "# 1. find corresponding utterances in reference set based on test set ...\n",
    "ref_utt, hyp_utt, sel_ids = eva.match_corpora(ref_utt,hyp_utt,ref_ids,hyp_ids)\n",
    "#ref_utt, sel_ids = eva.select_from_corpus(ref_utt, ref_ids,selection=hyp_ids)\n",
    "# 2. just in case that the test contained an utterance not in the reference ..\n",
    "#hyp_utt, _ = eva.select_from_corpus(hyp_utt, hyp_ids, selection = sel_ids)\n",
    "#\n",
    "assert(len(hyp_utt) == len(ref_utt))\n",
    "print(ref_ids,hyp_ids,sel_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate: 4.63% \n",
      "Error Details: #S=20 #I=5 #D=14\n",
      "Edit Distance: 41.00 \n",
      "Tokens (HYP): 834    (REF): 843 \n",
      "Utterances: 5\n"
     ]
    }
   ],
   "source": [
    "results = eva.eval_corpus(hyp_utt,ref_utt)\n",
    "assert(results['total']==39)\n",
    "eva.pp_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results after Normalization\n",
      "Error Rate: 4.27% \n",
      "Error Details: #S=18 #I=4 #D=14\n",
      "Edit Distance: 37.80 \n",
      "Tokens (HYP): 833    (REF): 843 \n",
      "Utterances: 5\n",
      "\n",
      "Results after Normalization and Compounding\n",
      "Error Rate: 3.20% \n",
      "Error Details: #S=12 #I=3 #D=12\n",
      "Accepted Compounds: #C=5\n",
      "Edit Distance: 29.20 \n",
      "Tokens (HYP): 833    (REF): 843 \n",
      "Utterances: 5\n"
     ]
    }
   ],
   "source": [
    "  #\n",
    "print(\"\\nResults after Normalization\")\n",
    "res1 = eva.eval_corpus(hyp_utt,ref_utt,norm=norm_nl)\n",
    "eva.pp_results(res1)\n",
    "#\n",
    "print(\"\\nResults after Normalization and Compounding\")\n",
    "res2 = eva.eval_corpus(hyp_utt,ref_utt,norm=norm_nl,CMPND=['','-'],ALIGN=True)\n",
    "eva.pp_results(res2)\n",
    "assert(round(res2['err'],2)==3.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ERROR ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitutions and Deletions in test2\n",
      "[('een', 'één', 'S'), ('_', 'en', 'D'), ('_', 'meer', 'D'), ('begroting', 'begroeting', 'S'), ('ballet', 'palais', 'S'), ('_', 'we', 'D'), ('russen', 'zullen', 'S'), ('liggen', 'je', 'S'), ('worden', 'woede', 'S'), ('er', 'het', 'S'), ('_', 'nu', 'D'), ('_', 'ze', 'D'), ('_', 'een', 'D'), ('verloor', 'verloog', 'S'), ('antwerps', 'antwerpse', 'S'), ('dassen', 'dasse', 'S'), ('_', 'wel', 'D'), ('_', 'dat', 'D'), ('_', 'de', 'D'), ('_', 'de', 'D'), ('voren', 'voor', 'S'), ('_', 'de', 'D'), ('_', 'toch', 'D'), ('dassen', 'dasse', 'S')]\n",
      "Compounds found in test2\n",
      "[('laurent-désiré', 'laurent+désiré', 'C'), ('nul-twee', 'nul+twee', 'C'), ('vijftig+duizend', 'vijftigduizend', 'C'), ('zolang', 'zo+lang', 'C'), ('mini+koningskwestie', 'mini-koningskwestie', 'C')]\n"
     ]
    }
   ],
   "source": [
    "# look at selected errors WITHOUT compounding in res1 and resolved compounds in res2\n",
    "\n",
    "print('Substitutions and Deletions in test2')\n",
    "err_sd = [ error for error in res2['errors'] if (error[2] in ['S','D']) ]\n",
    "print(err_sd)\n",
    "print('Compounds found in test2')\n",
    "errc = [ error for error in res2['errors'] if (error[2] in ['C']) ]\n",
    "print(errc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dutch ASR Evaluation for NBest and CGN benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MINI-CGN DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD ERROR RATE\n",
      "Error Rate: 36.43% \n",
      "Error Details: #S=34 #I=7 #D=10\n",
      "Edit Distance: 54.40 \n",
      "Tokens (HYP): 137    (REF): 140 \n",
      "Utterances: 5\n",
      "CHARACTER ERROR RATE\n",
      "Error Rate: 17.74% \n",
      "Error Details: #S=46 #I=50 #D=47\n",
      "Edit Distance: 147.60 \n",
      "Tokens (HYP): 809    (REF): 806 \n",
      "Utterances: 5\n"
     ]
    }
   ],
   "source": [
    "# Get subset from NBest ready\n",
    "ref_utt = eva.read_corpus(testdata+\"cgndev1_ref.txt\")\n",
    "hyp_utt = eva.read_corpus(testdata+\"cgndev1_asr1.txt\")\n",
    "res_word = eva.eval_corpus(hyp_utt,ref_utt)\n",
    "res_char = eva.eval_corpus(hyp_utt,ref_utt,TOKEN=\"CHAR\")\n",
    "print(\"WORD ERROR RATE\")\n",
    "eva.pp_results(res_word)\n",
    "print(\"CHARACTER ERROR RATE\")\n",
    "eva.pp_results(res_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NBest dev-set (full)\n",
    "Showing error rate reduction from 8.3% to 4.3%  by Normalization and Compound processing !!   \n",
    "This test takes some time (a few minutes) depending on the speech of your machine. Cause is the very long paragraph length\n",
    "utterances (> 100 words/paragraph) that need to be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw Error Rate\n",
      "Error Rate: 8.31% \n",
      "Error Details: #S=519 #I=220 #D=119\n",
      "Edit Distance: 909.90 \n",
      "Tokens (HYP): 10425    (REF): 10324 \n",
      "Utterances: 71\n",
      "\n",
      "Error Rate after normalization\n",
      "Error Rate: 6.24% \n",
      "Error Details: #S=373 #I=151 #D=120\n",
      "Edit Distance: 681.30 \n",
      "Tokens (HYP): 10350    (REF): 10319 \n",
      "Utterances: 71\n",
      "\n",
      "Error Rate after normalization and allowing for compounds\n",
      "Error Rate: 4.32% \n",
      "Error Details: #S=268 #I=73 #D=105\n",
      "Accepted Compounds: #C=101\n",
      "Edit Distance: 493.00 \n",
      "Tokens (HYP): 10350    (REF): 10319 \n",
      "Utterances: 71\n"
     ]
    }
   ],
   "source": [
    "ref_file = testdata+\"nbdev_ref.txt\"\n",
    "hyp_file = testdata+\"nbdev_asr100.txt\"\n",
    "ref_utt, ref_ids = eva.read_corpus(ref_file,KEYS=True)\n",
    "hyp_utt, hyp_ids = eva.read_corpus(hyp_file,KEYS=True)\n",
    "\n",
    "print(\"\\nRaw Error Rate\")\n",
    "results1 = eva.eval_corpus(hyp_utt,ref_utt)\n",
    "eva.pp_results( results1 )\n",
    "print(\"\\nError Rate after normalization\")\n",
    "eva.pp_results( eva.eval_corpus(hyp_utt,ref_utt,norm=norm_nl) )\n",
    "print(\"\\nError Rate after normalization and allowing for compounds\")\n",
    "results3 = eva.eval_corpus(hyp_utt,ref_utt,norm=norm_nl,CMPND=['','-']) \n",
    "eva.pp_results(results3)\n",
    "assert( round(results1['err'],2) == 8.31 )\n",
    "assert( round(results3['err'],2) == 4.32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
