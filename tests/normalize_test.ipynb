{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST-SCRIPT for Normalizer class in the normalization module\n",
    "\n",
    "The Normalizer class includes common normalization operations that is useful in the context of ASR evaluation and other applications requiring literal text comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, sys, os, copy\n",
    "import pkg_resources\n",
    "import evalign as eva\n",
    "#\n",
    "data_nl = pkg_resources.resource_filename('evalign', 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module evalign.normalize in evalign:\n",
      "\n",
      "NAME\n",
      "    evalign.normalize\n",
      "\n",
      "DESCRIPTION\n",
      "    @author:  compi\n",
      "    @version: 0.1\n",
      "    @revised: 23/11/2022\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        Normalizer\n",
      "    \n",
      "    class Normalizer(builtins.object)\n",
      "     |  Summary:\n",
      "     |  --------\n",
      "     |  The Normalizer class delivers a set of text normalization operations\n",
      "     |  that are handy in ASR (and NLP) evaluations\n",
      "     |  \n",
      "     |  A Normalizer object is formed by adding elementary operations \n",
      "     |  to the processing pipeline.\n",
      "     |  \n",
      "     |  Normalization can then be applied to a string or corpus (list of strings)\n",
      "     |  by calling Normalizer.process(text)\n",
      "     |  \n",
      "     |  The elementary opertions are:\n",
      "     |      ToLowerCase          convert to lower case\n",
      "     |      ToUpperCase          convert to upper case\n",
      "     |      ReduceWhiteSpace    converts all white space in between words to single blank \n",
      "     |      DeleteTags           delete all XML like tagged tokens (i.e. between <>)\n",
      "     |      SubstitutePatterns   (recursive) pattern substitution, may include space and punctuation\n",
      "     |                              The loop is over the patters, hence substitutions can be applied recursively\n",
      "     |      SubstituteWords      (single) word substitutions (word=: anything between white space)\n",
      "     |                              The loop is over the words of the input; single substitution per word \n",
      "     |      StripHyphen              removes word initial or final hyphenation character\n",
      "     |      SplitHyphen              decompound hyphenated words\n",
      "     |      CompoundOnChar           compound words marked with COMPOUND_CHAR\n",
      "     |    \n",
      "     |  Special Characters:\n",
      "     |  -------------------\n",
      "     |      HYPHEN_CHAR     : denotes hyphenation, default = '-'\n",
      "     |      COMPOUND_CHAR   : denotes optional compounding, default = '_'\n",
      "     |      TAG_CHARS       : encloses tags, default = '<>'\n",
      "     |      PARSING_CHAR    : parsing character in substitution files\n",
      "     |      \n",
      "     |      In general it is assumed that everything will be most robust if the defaults\n",
      "     |      are preserved for these special characters. In some routines it is possible to redefine these characters.\n",
      "     |      \n",
      "     |  Attributes:\n",
      "     |  -----------\n",
      "     |      pipe_names: list, default = []\n",
      "     |          list of str with operand name\n",
      "     |      pipe_args:\n",
      "     |          list with arguments to the operands, typically dict or None\n",
      "     |  \n",
      "     |  Methods:\n",
      "     |  --------\n",
      "     |      add_pipe(name,arg):     add operation 'name' with arguments 'arg' to the pipe\n",
      "     |      info():                 prints pipeline and arguments\n",
      "     |      process(text):          process a text through the pipeline. 'text' is a single string\n",
      "     |                                  or list\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  add_pipe(self, proc_step, arg=None)\n",
      "     |  \n",
      "     |  info(self)\n",
      "     |      Print the processing pipeline and its arguments\n",
      "     |  \n",
      "     |  process(self, text)\n",
      "     |  \n",
      "     |  process_string(self, s)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    DecompHyphen(s, arg=None)\n",
      "    \n",
      "    Lower(s, arg=None)\n",
      "    \n",
      "    MakeCompounds(s, arg=None)\n",
      "    \n",
      "    RemovePunctuation(s, arg=None)\n",
      "        # Remove (multiple) Punctuation Characters if at end of line or followed by white space, i.e. leave them word internal\n",
      "    \n",
      "    RemoveTags(s, arg=None)\n",
      "    \n",
      "    RemoveWhiteSpace(s, arg=None)\n",
      "    \n",
      "    SplitHyphen(s, arg=None)\n",
      "    \n",
      "    StripHyphen(s, arg=None)\n",
      "    \n",
      "    Substitute(s, arg)\n",
      "    \n",
      "    SubstituteRegex(s, arg=None)\n",
      "    \n",
      "    SubstituteWords(s, arg)\n",
      "    \n",
      "    Upper(s, arg=None)\n",
      "\n",
      "FILE\n",
      "    c:\\users\\compi\\nextcloud\\github\\evalign\\evalign\\normalize.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(eva.normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Example\n",
    "This example shows how to implement the accepted normalization for the ASR NBEST test suite for Dutch(BE) with the \n",
    "Normalizer class.   \n",
    "\n",
    "A pipeline normalization process is defined, consisting of:   \n",
    "- removing all additional white space\n",
    "- normalizing define abbreviations\n",
    "- normalizing fillers\n",
    "    + e.g. uh --> \\<h\\>\n",
    "- rewrite rules for Dutch numbers < 100  (is a complement to the ASR routine that generates parts of numbers)\n",
    "    + e.g. één-en tachtig -->  eenentachtig\n",
    "- normalizing for spelling variants in the NBEST test set\n",
    "    + e.g. E negentien --> E19\n",
    "- remove all tags (normalized fillers)\n",
    "- convert to lower case   \n",
    "\n",
    "The normalization with the **norm** object is applied to a raw text **text_raw** by simply running:\n",
    ">  text_norm = norm.process(text_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--INPUT:  \n",
      "de rijweg is vrij op de E negentien Antwerpen Brussel in de Craeybeckxtunnel \n",
      "\n",
      "uh uh een goede morgen \n",
      "       \n",
      "\n",
      "Antwerpen-Charleroi eindigde op  één-en tachtig drie-en zestig\n",
      "\n",
      "de rijweg is vrij op de e19 antwerpen brussel in de craeybeckxtunnel een goede morgen antwerpen-charleroi eindigde op eenentachtig drieënzestig\n"
     ]
    }
   ],
   "source": [
    "text_raw=\"\"\"de rijweg is vrij op de E negentien Antwerpen Brussel in de Craeybeckxtunnel \\n\n",
    "uh uh een goede morgen \\n       \\n\n",
    "Antwerpen-Charleroi eindigde op  één-en tachtig drie-en zestig\n",
    "\"\"\"\n",
    "print(\"--INPUT:  \")\n",
    "print(text_raw)\n",
    "# 1. \n",
    "# Load specifications from files (or create them here), read functions are defined in evalign.utils\n",
    "nl_abbrev = eva.LoadSubstitutionsFromFile(data_nl+'nl_abbrev.lst')\n",
    "cgn_fillers = eva.LoadSubstitutionsFromFile(data_nl+'cgn_fillers.lst')\n",
    "nl_getallen100 = eva.LoadSubstitutionsFromFile(data_nl+'nl_getallen100.lst')\n",
    "nbest = eva.LoadSubstitutionsFromFile(data_nl+'nbest.lst')\n",
    "# 2. \n",
    "# initialize a Normalizer object\n",
    "# and define a processing pipe by adding elementary operations with their parameters  \n",
    "norm = eva.Normalizer()\n",
    "norm.add_pipe(\"RemovePunctuation\")\n",
    "norm.add_pipe(\"SubstituteWords\",cgn_fillers)\n",
    "norm.add_pipe(\"SubstituteWords\",nl_abbrev)\n",
    "norm.add_pipe(\"Substitute\",nl_getallen100)\n",
    "norm.add_pipe(\"Substitute\",nbest)\n",
    "norm.add_pipe(\"RemoveTags\")\n",
    "norm.add_pipe(\"Lower\")\n",
    "norm.add_pipe(\"RemoveWhiteSpace\")\n",
    "nbest_norm = copy.deepcopy(norm)\n",
    "# 3.\n",
    "# run the normalizer on a raw text input\n",
    "text_norm = norm.process(text_raw)\n",
    "print(text_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Elementary Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### RemovePunctuation\n",
    "removes white space and the most common punctuations **.,!?:;**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "  This is a sentence with spaces   , tabs \t and line breaks \n",
      "  Get rid of all Punctuation !!?  except: when word,internal.\n",
      "output:\n",
      "  This is a sentence with spaces    tabs \t and line breaks \n",
      "  Get rid of all Punctuation   except when word,internal\n"
     ]
    }
   ],
   "source": [
    "text = \" This is a sentence with spaces   , tabs \\t and line breaks \\n  Get rid of all Punctuation !!?  except: when word,internal.\"\n",
    "print(\"input:\\n\", text)\n",
    "Norm = eva.Normalizer()\n",
    "Norm.add_pipe(\"RemovePunctuation\")\n",
    "text_norm = Norm.process(text)\n",
    "print(\"output:\\n\", text_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### RemoveWhiteSpace\n",
    "removes all redundant white space, including line breaks ; i.e. input is considered one utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "  This is a sentence with spaces   , tabs \t and line breaks \n",
      "  Get rid of them !!\n",
      "output:\n",
      " This is a sentence with spaces , tabs and line breaks Get rid of them !!\n"
     ]
    }
   ],
   "source": [
    "text = \" This is a sentence with spaces   , tabs \\t and line breaks \\n  Get rid of them !!\"\n",
    "print(\"input:\\n\", text)\n",
    "norm = eva.Normalizer()\n",
    "norm.add_pipe(\"RemoveWhiteSpace\")\n",
    "text_norm = norm.process(text)\n",
    "print(\"output:\\n\", text_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substitute\n",
    "**Substitute** implements generic pattern substitutions applied in the order specified on the full text (word, word internal, cross word). \n",
    "Substitute patterns can hence contain blanks.  \n",
    "Given the broad scope, Substitute substitutions should be applied with great care to avoid unexpected modifications. \n",
    "Substitute substitutions are executed one by one, hence an original fragment may be modified multiple times\n",
    "\n",
    "In this example numbers (written in the decompounded format used in the ESAT ASR system) are compounded in 2 steps: (1) rewriting of the first part with compounding final char (2) compound acceptance by the second part of the compound\n",
    "\n",
    "#### SubstituteWords\n",
    "**SubstituteWords** is a substitution applied to words (surrounded by white space). \n",
    "This is more robust and easier to scope than the more generic **Substitute**  substitutions.\n",
    "However, be aware, that in the current implementation sentences all extraneous white space gets lost by this routine.\n",
    "\n",
    "In this example, a file with filler normalizations into tags \\<h\\> and \\<g\\> is loaded and applied.\n",
    "    \n",
    "#### Loading Substitution Patters from file\n",
    "Both **Substitute** and **SubstituteWords** require definitions of the target and substitution patterns.  These are passed to the Normalizer as Python dictionaries.\n",
    "In the **util** module , a routine **SubstitutionsFromFile** is available. The file\n",
    "should hold one substitution pattern per line with patterns to be parsed by '|'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      " vijf-en twintig duizend drie honderd drie-en tachtig\n",
      "{'één-en': 'eenen_', 'twee-en': 'tweeën_', 'drie-en': 'drieën_', 'vier-en': 'vieren_', 'vijf-en': 'vijfen_', 'zes-en': 'zesen_', 'zeven-en': 'zevenen_', 'acht-en': 'achten_', 'negen-en': 'negenen_', 'n_ twintig': 'ntwintig', 'n_ dertig': 'ndertig', 'n_ veertig': 'nveertig', 'n_ vijftig': 'nvijftig', 'n_ zestig': 'nzestig', 'n_ zeventig': 'nzeventig', 'n_ tachtig': 'ntachtig', 'n_ negentig': 'nnegentig'}\n",
      "output:\n",
      " vijfentwintig duizend drie honderd drieëntachtig\n"
     ]
    }
   ],
   "source": [
    "text = \"vijf-en twintig duizend drie honderd drie-en tachtig\"\n",
    "Norm = eva.Normalizer()\n",
    "print(\"input:\\n\", text)\n",
    "Norm.add_pipe(\"RemoveWhiteSpace\")\n",
    "nl_getallen100 = eva.LoadSubstitutionsFromFile(data_nl+'nl_getallen100.lst')\n",
    "Norm.add_pipe(\"Substitute\",nl_getallen100)\n",
    "Norm.pipe=[\"single_space\",\"sub_patterns\"]\n",
    "text_norm = Norm.process(text)\n",
    "print(nl_getallen100)\n",
    "print(\"output:\\n\", text_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      " Fillers zoals xxx uh he ggg,ggg  kunnen we reduceren tot een aantal minimale tags \n",
      "output:\n",
      " Fillers zoals <x> <h> <h> <g>  kunnen we reduceren tot een aantal minimale tags \n"
     ]
    }
   ],
   "source": [
    "text = \"Fillers zoals xxx uh he ggg,ggg  kunnen we reduceren tot een aantal minimale tags \"\n",
    "print(\"input:\\n\", text)\n",
    "Norm = eva.Normalizer()\n",
    "word_substitutions = eva.LoadSubstitutionsFromFile(data_nl+'cgn_fillers.lst')\n",
    "Norm.add_pipe(\"SubstituteWords\",word_substitutions)\n",
    "# to see the standard number substitutions\n",
    "# print(word_substitutions)\n",
    "text_norm = Norm.process(text)\n",
    "print(\"output:\\n\", text_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RemoveTags\n",
    "   \n",
    "**RemoveTags** will remove all tags of the form **\\<???\\>** from the text.  Such tags  may not be part of the text as such as they are commonly used for meta-information, class descriptors, non-speech events, sentence and speaker boundaries etc.     \n",
    "In the implementation there is an inherent assumption that tags are at most 32 characters to avoid collusion with (unlikely) standalone < or > characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      " All HTML like tags like <h> <g> for fillers and others like <SPKR ID=M13> </SPKR> and <UNK> and <br> or line end and start <s> and </s>     can be deleted with a single call but not <012345678901234567890123456789012> which is too long\n",
      "output:\n",
      " All HTML like tags like   for fillers and others like   and  and  or line end and start  and      can be deleted with a single call but not <012345678901234567890123456789012> which is too long\n"
     ]
    }
   ],
   "source": [
    "text = \"All HTML like tags like <h> <g> for fillers and others like <SPKR ID=M13> </SPKR> and <UNK> and <br> or line end and start <s> and </s> \\\n",
    "    can be deleted with a single call but not <012345678901234567890123456789012> which is too long\"\n",
    "print(\"input:\\n\", text)\n",
    "Norm = eva.Normalizer()\n",
    "Norm.add_pipe(\"RemoveTags\")\n",
    "text_norm=Norm.process(text)\n",
    "print(\"output:\\n\", text_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StripHyphen and SplitHyphen\n",
    "**StripHyphen** will remove all hyphens in word-initial and word-final positions    \n",
    "**SplitHyphen** splits hyphen-compounds into their parts\n",
    "**DecompHyphen** splits hypen-compounds and attach '\\_' to the compounding edges \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      " De ex-gouverneur laat appel- en perencontainers plaatsen\n",
      "output (strip):\n",
      " De ex-gouverneur laat appel en perencontainers plaatsen\n",
      "output (split):\n",
      " De ex gouverneur laat appel- en perencontainers plaatsen\n",
      "output (split):\n",
      " De ex_ _gouverneur laat appel_ en perencontainers plaatsen\n"
     ]
    }
   ],
   "source": [
    "text = \"De ex-gouverneur laat appel- en perencontainers plaatsen\"\n",
    "print(\"input:\\n\", text)\n",
    "Norm = eva.Normalizer()\n",
    "Norm.add_pipe(\"StripHyphen\")\n",
    "text_norm=Norm.process(text)\n",
    "print(\"output (strip):\\n\", text_norm)\n",
    "Norm = eva.Normalizer()\n",
    "Norm.add_pipe(\"SplitHyphen\")\n",
    "text_norm=Norm.process(text)\n",
    "print(\"output (split):\\n\", text_norm)\n",
    "Norm = eva.Normalizer()\n",
    "Norm.add_pipe(\"DecompHyphen\")\n",
    "text_norm=Norm.process(text)\n",
    "print(\"output (split):\\n\", text_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other functions and Special Characters\n",
    "\n",
    "There are a few other functions supported:\n",
    "> **lower**: conversion to lower case   \n",
    "> **upper**: conversion to upper case\n",
    " \n",
    "A few characters have a reserved meaning in Normalizer and should be used with care\n",
    "> '|' is used as separator in the substitution files   \n",
    "> '<>' is used to determine tags   \n",
    "> '_'  plays a role in certain compounding routines   \n",
    "> '\\' the input string and the substitution patterns can be escaped character sequences   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      " Escape characters like backslash-t(\t) and backslash-n(\n",
      ") are allowed \n",
      "but be careful with single backslash(\\) AND the sequence of operations !! \n",
      "output:\n",
      " Escape characters like backslash-t(<TAB>) and backslash-n(<NEWLINE>) are allowed <NEWLINE>but be careful with single backslash(<BS>) AND the sequence of operations !! \n"
     ]
    }
   ],
   "source": [
    "#  Remark in the text below the '\\' and '\\\\' in isolation yielding the same input\n",
    "text = \"\"\"Escape characters like backslash-t(\\t) and backslash-n(\\n) are allowed \n",
    "but be careful with single backslash(\\\\) AND the sequence of operations !! \"\"\"\n",
    "print(\"input:\\n\", text)\n",
    "Norm = eva.Normalizer()\n",
    "special_chars =  {\"\\t\":\"<TAB>\", \"\\n\":\"<NEWLINE>\", '\\\\':\"<BS>\"}\n",
    "Norm.add_pipe(\"Substitute\",special_chars)\n",
    "text_norm=Norm.process(text)\n",
    "print(\"output:\\n\", text_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples for Dutch from CGN and NBEST \n",
    "#### Nederlandse getallen > 100 en in alle contexten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in het jaar dertien honderd veertien reden twee honderd vijfentwintig duizend honderd en acht kruisvaarders tweeëntwintig keer tweeën_ half uur lang\n",
      "in het jaar dertien honderd veertien reden twee honderd vijfentwintig duizend honderd en acht kruisvaarders tweeëntwintig keer tweeën  half uur lang\n"
     ]
    }
   ],
   "source": [
    "# 1. apply number rewriting in Dutch 1-100 as foreseen in the\n",
    "# Nbest normalizer above\n",
    "#\n",
    "text = \"In het jaar dertien honderd veertien  reden twee honderd vijf-en twintig duizend honderd en acht kruisvaarders twee-en twintig keer twee-en  half uur lang \"\n",
    "text1=nbest_norm.process(text)\n",
    "print(text1)\n",
    "# 2.\n",
    "# in this case the recognizer came up with un unusual sequence (in this case twee-en not followed by a teens number)\n",
    "#    some spurious compounding charcters '_'can creep into the code; \n",
    "#    they are easily removed assuming that they do not have any meaningful occurences\n",
    "norm_cleanup = eva.Normalizer()\n",
    "norm_cleanup.add_pipe(\"Substitute\",{'_':' '})\n",
    "text2=norm_cleanup.process(text1)\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " wel ik denk dat de keuze nu ook uhm uhm gebaseerd is op op meer inhoudelijke argumenten\n",
      "wel ik denk dat de keuze nu ook gebaseerd is op op meer inhoudelijke argumenten\n",
      "--\n",
      " dus we hadden de vorige keer dat die lijst tot stand is gekomen was eigenlijk gewoon uh alle Erasmuspartners die we toen hadden die uh hadden we toen aangeschreven\n",
      "dus we hadden de vorige keer dat die lijst tot stand is gekomen was eigenlijk gewoon alle erasmuspartners die we toen hadden die hadden we toen aangeschreven\n",
      "--\n",
      " dus nu is het ..\n",
      "dus nu is het\n",
      "--\n",
      " dus nu hebben we uhm ja op inhoudelijke xxx ..\n",
      "dus nu hebben we ja op inhoudelijke\n",
      "--\n",
      " en 't is dus ook de bedoeling om om die lijst te laten aangroeien\n",
      "en het is dus ook de bedoeling om om die lijst te laten aangroeien\n",
      "--\n",
      " dus uh als er nieuwe groepen zijn die we moeten aanschrijven\n",
      "dus als er nieuwe groepen zijn die we moeten aanschrijven\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " xxx\n",
      "\n",
      "--\n",
      " Steven uh organiseert een uh workshop ook\n",
      "steven organiseert een workshop ook\n",
      "--\n",
      " uhm je bedoelt het probleem met D-blok hier\n",
      "je bedoelt het probleem met d-blok hier\n",
      "--\n",
      " maar dat is dus iets waar wij ook uh ..\n",
      "maar dat is dus iets waar wij ook\n",
      "--\n",
      " ja maar dat is wat nu eigenlijk gebeurt ook hè\n",
      "ja maar dat is wat nu eigenlijk gebeurt ook\n",
      "--\n",
      " dus alle onkosten die uh ..\n",
      "dus alle onkosten die\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " ja maar dat ..\n",
      "ja maar dat\n",
      "--\n",
      " dat is niet echt voorzien omdat ze daar dus ook bewijsmateriaal voor nodig hebben dat dat uhm gebaseerd is op op uh werkelijke uitgaven die passen binnen binnen CLIF\n",
      "dat is niet echt voorzien omdat ze daar dus ook bewijsmateriaal voor nodig hebben dat dat gebaseerd is op op werkelijke uitgaven die passen binnen binnen clif\n",
      "--\n",
      " maar ik kan het wel 'ns uh nakijken of het eventueel zou kunnen\n",
      "maar ik kan het wel eens nakijken of het eventueel zou kunnen\n",
      "--\n",
      " 't is misschien een manier om het probleem te omzeilen maar uh ik xxx ..\n",
      "het is misschien een manier om het probleem te omzeilen maar ik\n",
      "--\n",
      " oké dan 't belangrijkste agendapunt uh zeggen we xxx behalve het STWW-uh-oproep is de planning van de activiteiten dit jaar\n",
      "oké dan het belangrijkste agendapunt zeggen we behalve het stww-uh-oproep is de planning van de activiteiten dit jaar\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " ja dus ik had wel trouwens de indruk dat het uh verbeterd was\n",
      "ja dus ik had wel trouwens de indruk dat het verbeterd was\n",
      "--\n",
      " dus uh m'n eigen onkosten die worden nu toch binnen anderhalve maand of zo terugbetaald\n",
      "dus m'n eigen onkosten die worden nu toch binnen anderhalve maand of zo terugbetaald\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " ja xxx ..\n",
      "ja\n",
      "--\n",
      " ik zal s ..\n",
      "ik zal s\n",
      "--\n",
      " uhm ik denk ja dat hangt er dus van af of het uh de ene of de andere boekhouding is\n",
      "ik denk ja dat hangt er dus van af of het de ene of de andere boekhouding is\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " ja maar jullie werken niet voor deze universiteit dus uh ..\n",
      "ja maar jullie werken niet voor deze universiteit dus\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " oké xxx ..\n",
      "oké\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " dus da daar is 't uh xxx ..\n",
      "dus da daar is het\n",
      "--\n",
      " ja oké dus ik ik uh onthoud dat er een probleem is met de terugbetaling en dat we dat probleem probleren op te lossen hetzij door uh delegatie van subbudgetten of door één of andere constructie met uh reisbureaus of VZW's en bedrijven die we zelf in uh het eiland Man oprichten en zo\n",
      "ja oké dus ik ik onthoud dat er een probleem is met de terugbetaling en dat we dat probleem probleren op te lossen hetzij door delegatie van subbudgetten of door één of andere constructie met reisbureaus of vzw's en bedrijven die we zelf in het eiland man oprichten en zo\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " of is dat ..\n",
      "of is dat\n",
      "--\n",
      " xxx\n",
      "\n",
      "--\n",
      " oké uh nog meer activiteiten\n",
      "oké nog meer activiteiten\n",
      "--\n",
      " van Georges De Schutter hoorde ik dat uh informeel door dat hij gehoord had van mensen die de voorstellen be beoordeelt uhm dus dat we op één punt redelijk negatief beoordeeld waren\n",
      "van georgess de schutter hoorde ik dat informeel door dat hij gehoord had van mensen die de voorstellen be beoordeelt dus dat we op één punt redelijk negatief beoordeeld waren\n",
      "--\n",
      " dat was dat dat uh sommigen van die reviewers vonden dat we meer een soort van vriendenclub waren\n",
      "dat was dat dat sommigen van die reviewers vonden dat we meer een soort van vriendenclub waren\n",
      "--\n",
      " dus dat we xxx onderzoeksinitiatieven ..\n",
      "dus dat we onderzoeksinitiatieven\n",
      "--\n",
      " uhm dus er moet geld opgemaakt worden\n",
      "dus er moet geld opgemaakt worden\n",
      "--\n",
      " dus ik denk dat we dat dan gewoon een aandachtspunt moeten maken ook voor dus dat we proberen om om vooral op Europees niveau met onze buitenlandse partners dus uh allerlei onderzoeksprojecten op Europees niveau op te starten xxx of uh ook intern\n",
      "dus ik denk dat we dat dan gewoon een aandachtspunt moeten maken ook voor dus dat we proberen om om vooral op europees niveau met onze buitenlandse partners dus allerlei onderzoeksprojecten op europees niveau op te starten of ook intern\n",
      "--\n",
      " dus daar zijn we nu goed mee bezig ook met uh ja allerlei fondsen over de verschillende instellingen projecten initiëren\n",
      "dus daar zijn we nu goed mee bezig ook met ja allerlei fondsen over de verschillende instellingen projecten initiëren\n",
      "--\n",
      " xxx criterium xxx\n",
      "criterium\n",
      "--\n",
      " ggg\n",
      "\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " ja i ik denk dat xxx ..\n",
      "ja i ik denk dat\n",
      "--\n",
      " ja we moeten zeker denk ik blijven verder gaan met het uitnodigen van mensen voor uh lezingen ook\n",
      "ja we moeten zeker denk ik blijven verder gaan met het uitnodigen van mensen voor lezingen ook\n",
      "--\n",
      " mmm\n",
      "\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " dus xxx zij verwachten echt uh dat er uh dat wij op één xxx bepalen wat er de de speerpunten en de belangrijke lacunes zijn en daar ook iets aan doen\n",
      "dus zij verwachten echt dat er dat wij op één bepalen wat er de de speerpunten en de belangrijke lacunes zijn en daar ook iets aan doen\n",
      "--\n",
      " xxx\n",
      "\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " misschien moeten we dat dan iets breder aankondigen en en uh uh wat meer zelf ook de discipline opbrengen om ook naar die evenementen toe te komen\n",
      "misschien moeten we dat dan iets breder aankondigen en en wat meer zelf ook de discipline opbrengen om ook naar die evenementen toe te komen\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " zijn er nog uhm nog meer ideeën voor initiatieven die we kunnen nemen of ..\n",
      "zijn er nog nog meer ideeën voor initiatieven die we kunnen nemen of\n",
      "--\n",
      " ja dus we hebben een aantal grote workshops dus de Corsendonk Twee en de annotatie- of taggingworkshop\n",
      "ja dus we hebben een aantal grote workshops dus de corsendonk twee en de annotatie- of taggingworkshop\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " en we hadden dus afgesproken dat uh dat we ook proberen om een dagsymposium dat elke groep een dagsymposium probeert te organiseren dit jaar dus met een xxx cluster van een twee- à drietal sprekers die uh dus liefst ook gedeeltelijk uit onze buitenlandse partners worden gerekruteerd\n",
      "en we hadden dus afgesproken dat dat we ook proberen om een dagsymposium dat elke groep een dagsymposium probeert te organiseren dit jaar dus met een cluster van een twee- à drietal sprekers die dus liefst ook gedeeltelijk uit onze buitenlandse partners worden gerekruteerd\n",
      "--\n",
      " en d'r was het voorstel van Brussel om uh een workshop symposium over evolutie van taal te organiseren\n",
      "en er was het voorstel van brussel om een workshop symposium over evolutie van taal te organiseren\n",
      "--\n",
      " we xxx bij massa projecten initiëren\n",
      "we bij massa projecten initiëren\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " mmm\n",
      "\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " uhm oud geld en nieuw geld\n",
      "oud geld en nieuw geld\n",
      "--\n",
      " en Corsendonk zal najaar zijn hè\n",
      "en corsendonk zal najaar zijn\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " dus dat zou een eendaagse daagse workshop ..\n",
      "dus dat zou een eendaagse daagse workshop\n",
      "--\n",
      " ja ik heb dus wel de indruk dat aangezien we nu uh een flink aantal groepen d'rbij hebben dus dat het iets minder moeilijk zal worden om om de middelen ook nuttig te besteden\n",
      "ja ik heb dus wel de indruk dat aangezien we nu een flink aantal groepen d'rbij hebben dus dat het iets minder moeilijk zal worden om om de middelen ook nuttig te besteden\n",
      "--\n",
      " Frieda Steurs die uh laat niks van zich horen\n",
      "frieda steurs die laat niks van zich horen\n",
      "--\n",
      " die bel ik wel 'ns op\n",
      "die bel ik wel eens op\n",
      "--\n",
      " uhm dus ik weet niet of ..\n",
      "dus ik weet niet of\n",
      "--\n",
      " nu wat ik wel denk ik uh of wat we allemaal belangrijk zouden moeten vinden is dat we onze uh buitenlandse groepen wat beter te betrekken bij de werking van CLIF\n",
      "nu wat ik wel denk ik of wat we allemaal belangrijk zouden moeten vinden is dat we onze buitenlandse groepen wat beter te betrekken bij de werking van clif\n",
      "--\n",
      " tot hier toe xxx ..\n",
      "tot hier toe\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " hm\n",
      "\n",
      "--\n",
      " xxx nog een paar andere mensen zien uh dan is voor hun de drempel ook wat lager dan wanneer dat ze xxx komen om hun lezingetje te geven uh en dan teruggaan\n",
      "nog een paar andere mensen zien dan is voor hun de drempel ook wat lager dan wanneer dat ze komen om hun lezingetje te geven en dan teruggaan\n",
      "--\n",
      " wat minder in de breedte en wat xxx ..\n",
      "wat minder in de breedte en wat\n",
      "--\n",
      " nu misschien moeten wij ook uh de andere weg een keer meer bewandelen dat wij een aanbod doen aan bijvoorbeeld groepen dat we zeggen kijk wij kunnen daar vanuit CLIF bij jullie ook een paar lezingen komen geven\n",
      "nu misschien moeten wij ook de andere weg een keer meer bewandelen dat wij een aanbod doen aan bijvoorbeeld groepen dat we zeggen kijk wij kunnen daar vanuit clif bij jullie ook een paar lezingen komen geven\n",
      "--\n",
      " wij gaan d'r altijd vanuit dat wij zelf niks hebben en uh en dat de anderen naar hier moeten komen om iets uh om ons iets te leren maar uh zij kunnen dat ook even even interessant vinden dat ..\n",
      "wij gaan er altijd vanuit dat wij zelf niks hebben en en dat de anderen naar hier moeten komen om iets om ons iets te leren maar zij kunnen dat ook even even interessant vinden dat\n",
      "--\n",
      " xxx ..\n",
      "\n",
      "--\n",
      " xxx wij betalen ee een uh ..\n",
      "wij betalen ee een\n",
      "--\n",
      " nee zij betalen dan xxx deelname in CLIF maar goed 't zijn eigenlijk wij die betalen maar uh ..\n",
      "nee zij betalen dan deelname in clif maar goed het zijn eigenlijk wij die betalen maar\n",
      "--\n",
      " xxx d'r zijn weinig zendingen naar 't buitenland\n",
      "er zijn weinig zendingen naar het buitenland\n",
      "--\n",
      " maar dus als xxx ..\n",
      "maar dus als\n",
      "--\n",
      " waarom delegeren jullie geen deel van het budget uh naar uhm de groepen\n",
      "waarom delegeren jullie geen deel van het budget naar de groepen\n",
      "--\n",
      " wij doen dat nu binnen het CGN toch ook\n",
      "wij doen dat nu binnen het cgn toch ook\n",
      "--\n",
      " alle budgetten komen xxx\n",
      "alle budgetten komen\n",
      "--\n",
      " xxx zouden kunnen het budget op voorhand en in 't begin van 't jaar zegt ge ..\n",
      "zouden kunnen het budget op voorhand en in het begin van het jaar zegt ge\n",
      "--\n",
      " xxx\n",
      "\n",
      "--\n",
      " hè nu in deze periode de kerstboom is een fijnspar geen dennenboom\n",
      "nu in deze periode de kerstboom is een fijnspar geen dennenboom\n"
     ]
    }
   ],
   "source": [
    "corpus_fname = \"testdata/demo2_17_ref.txt\"\n",
    "utts, ids = eva.read_corpus(corpus_fname,KEYS=True)\n",
    "    \n",
    "for utt in utts:\n",
    "    utt_norm = nbest_norm.process(utt)\n",
    "    if utt_norm != utt:\n",
    "        print('--\\n',utt)\n",
    "        print(utt_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
